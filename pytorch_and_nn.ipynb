{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNdzuXWJ+a6UEDmceEZT+yj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratikchaudhari64/notebooks/blob/main/pytorch_and_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gOEavnr49phc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n"
      ],
      "metadata": {
        "id": "r2xineFx-WRr"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the ith image out of minibatch\n",
        "i = 1\n",
        "plt.imshow(training_data.data[:i].view(i, 784), aspect = 100)\n",
        "plt.show()\n",
        "# training_data.data[:i].view(1, 784)"
      ],
      "metadata": {
        "id": "t4E3rKsIEpD0",
        "outputId": "f54af6c0-bf9c-43a4-eaf5-e9d106099e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic forward pass.\n",
        " - **Input Layer**: training data had original tensor of (3,28,28) where the 28x28 matrix for each photo already has RGB encoded numbers. Then, flattened it out for each image to have 28*28 features (kinda,..) and then input is tensor (3,784)\n",
        " - **Hidden Layers**: layer1+relu; layer2+relu\n",
        " - **Output Layers**: (3,10) form tensor gets created first by introducing new linear layer (512, 10). Then, perform softmax to scale such that sum = 1(form probabilities), then finally test probability of your desired class (10 total classes returned with probability for each) against what it actually was"
      ],
      "metadata": {
        "id": "SJdro1CpAmYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "minibatch_size = 32\n",
        "\n",
        "train_minibatch = training_data.data[:minibatch_size]\n",
        "\n",
        "flattened_view = train_minibatch.view(minibatch_size, 784).type(torch.float32)\n",
        "print(f\"final input: {flattened_view.size()}\")                      # input photos get converted to numerical represenatation. One way to think\n",
        "                                                                    # to think is that each image is now represented as 784 feature columns (size: 3x784)\n",
        "\n",
        "\n",
        "layer1 = nn.Linear(in_features=28*28, out_features=512)\n",
        "hidden1 = layer1(flattened_view)\n",
        "hidden1_relu = nn.ReLU()(hidden1)\n",
        "print(f\"hidden1_relu: {hidden1_relu.size()}\")                       # First mixing of weights along\n",
        "                                                                    # with a ReLU (and oher things like batchnorm/dropouts etc.)\n",
        "\n",
        "layer_2 = nn.Linear(512, 512)\n",
        "hidden_2 = layer_2(hidden1_relu)\n",
        "hidden_2_relu = nn.ReLU()(hidden_2)\n",
        "print(f\"hidden2_relu: {hidden_2_relu.size()}\")                      # Second mixing of weights along\n",
        "                                                                    # with a ReLU (and oher things like batchnorm/dropouts etc.)\n",
        "\n",
        "\n",
        "layer_3 = nn.Linear(512, 10)\n",
        "output = layer_3(hidden_2_relu)\n",
        "print(f\"output: {output.size()}\")                                   # Finally converted to give pre-probabilities (think of these as counts)\n",
        "                                                                    # for each class (which in turn we want to maximize)\n",
        "loss = nn.functional.cross_entropy(output, training_data.targets[:minibatch_size])\n",
        "print(loss)\n",
        "loss.backward()\n",
        "\n",
        "for layer in [layer1, layer_2, layer_3]:\n",
        "  for p in layer.parameters():\n",
        "    p.data = p.data - 0.01 * p.grad.data\n",
        "\n",
        "\n",
        "# softmaxed probabilities\n",
        "# softmax = nn.Softmax(dim=1)\n",
        "# probabilities = softmax(output)\n",
        "# print(f\"probabilities: {probabilities.size()}\")                     # counts found in previous example now got scaled to resemble probabilities\n",
        "# probabilities[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "uuTiUwC7LUsz",
        "outputId": "746b6718-360e-4fe4-97ba-ab6669b930f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final input: torch.Size([32, 784])\n",
            "hidden1_relu: torch.Size([32, 512])\n",
            "hidden2_relu: torch.Size([32, 512])\n",
            "output: torch.Size([32, 10])\n",
            "tensor(16.7956, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lay = nn.Linear(in_features=784, out_features=20)\n",
        "# print(lay.weight.size())\n",
        "# print(lay.bias.size())\n",
        "\n",
        "for param in [layer1, layer_2, layer_3]:\n",
        "    for p in param.parameters():\n",
        "        print(p.data)\n",
        "\n",
        "for i in layer1.parameters():\n",
        "  print(i)\n",
        "\n",
        "layer1.weight\n",
        "# dir(probabilities)\n",
        "# probabilities.grad\n",
        "# loss = nn.functional.cross_entropy(output, training_data.targets[:3])\n",
        "# loss"
      ],
      "metadata": {
        "id": "MnSHz9d5RAyY",
        "outputId": "decf857a-b1ac-425b-e6ad-9a74d7118cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-1.0868e-03,  2.6068e-02,  3.0116e-03,  ...,  2.3046e-02,\n",
            "          3.0558e-02,  2.7585e-02],\n",
            "        [ 2.1503e-02, -3.1856e-02,  3.2216e-02,  ...,  1.7353e-02,\n",
            "          1.1927e-02, -1.0294e-02],\n",
            "        [ 1.0987e-02, -9.9699e-03, -3.2709e-02,  ..., -2.7462e-02,\n",
            "          1.2825e-02, -6.8808e-03],\n",
            "        ...,\n",
            "        [-1.8730e-02,  3.2761e-05, -3.4977e-02,  ..., -2.8589e-03,\n",
            "          1.9963e-02,  2.8916e-02],\n",
            "        [-9.3056e-03,  3.2783e-02,  4.4921e-03,  ..., -2.7229e-02,\n",
            "          1.3071e-02, -2.8241e-04],\n",
            "        [-3.4494e-02, -2.9606e-03,  2.2455e-04,  ..., -2.1973e-02,\n",
            "         -2.3918e-02,  4.4296e-03]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-8.2297e-03, -2.9221e-02, -1.5031e-02,  7.7767e-03,  1.4928e-03,\n",
            "        -1.1382e-02, -2.2032e-02, -2.0942e-02, -1.3441e-02,  2.7542e-02,\n",
            "        -1.9204e-02, -2.4747e-02, -1.9584e-02, -1.7675e-02,  3.3758e-02,\n",
            "        -3.2228e-02, -5.0270e-03,  2.4905e-02,  2.9400e-03,  5.1760e-03,\n",
            "        -2.0473e-02, -2.0362e-02,  3.5335e-02,  2.3303e-02,  1.1097e-02,\n",
            "         1.8305e-02, -9.6434e-03,  1.5929e-02,  3.2225e-02,  1.6147e-02,\n",
            "        -1.4890e-02, -1.2866e-02,  1.8026e-02, -2.4613e-02,  8.7794e-03,\n",
            "         2.2029e-02, -1.4535e-02, -1.2723e-02,  6.3243e-03, -3.0420e-02,\n",
            "         1.9802e-02, -7.0141e-03,  8.1462e-03, -1.7618e-02,  2.5488e-02,\n",
            "         1.2894e-02,  6.8504e-03,  2.2428e-02,  3.5541e-02,  3.4562e-02,\n",
            "         3.4335e-02,  2.3931e-03,  2.4067e-02,  4.4015e-03,  2.7975e-02,\n",
            "        -3.2376e-02,  1.0656e-02, -3.4885e-02,  2.7097e-02,  2.8037e-02,\n",
            "         2.5576e-02,  1.9761e-02, -7.2771e-03,  1.5207e-02,  2.0594e-02,\n",
            "         2.7620e-02,  2.2735e-02,  2.7610e-03, -2.1433e-02,  2.7501e-02,\n",
            "        -1.7685e-02, -1.2568e-02, -3.4368e-02,  6.6119e-03,  2.3362e-02,\n",
            "         3.1261e-02, -3.2616e-04, -1.3356e-03,  1.8415e-02, -1.4888e-02,\n",
            "        -3.4940e-02,  1.6538e-02,  3.0611e-02, -1.3676e-02, -7.7415e-03,\n",
            "         2.7303e-02, -8.7249e-03,  1.2939e-02,  1.2059e-02, -3.2788e-02,\n",
            "        -2.7473e-02, -3.1531e-02, -3.5237e-02,  1.9551e-02, -7.8635e-03,\n",
            "        -1.5460e-02,  3.3832e-03, -3.4051e-02, -2.7619e-02,  5.4840e-03,\n",
            "        -1.5706e-02, -1.5987e-02,  2.7286e-02, -3.0477e-03,  2.1180e-03,\n",
            "         9.1646e-03, -7.3777e-03,  3.6858e-04, -5.3427e-04,  1.6115e-02,\n",
            "        -7.1297e-03, -3.0169e-03, -3.3744e-02, -3.3327e-04, -1.0884e-02,\n",
            "         1.1926e-02, -2.2078e-02,  3.2980e-02, -3.2314e-02, -3.1577e-02,\n",
            "        -2.3281e-02, -1.3049e-02,  2.6145e-02, -1.7167e-02,  1.4177e-02,\n",
            "        -9.3761e-03, -2.0515e-02,  7.1748e-03, -3.3515e-02,  2.4003e-02,\n",
            "         9.2957e-03,  5.6713e-03,  1.8947e-02,  5.8966e-04,  1.6088e-02,\n",
            "        -2.1376e-02, -5.5956e-05,  1.4147e-02, -7.8741e-03,  2.5194e-02,\n",
            "         2.8290e-02,  2.4073e-02,  3.4220e-02, -2.2237e-02,  2.3099e-02,\n",
            "         1.2275e-02,  1.9306e-02,  1.7865e-02,  1.4153e-02, -1.6422e-02,\n",
            "        -9.8825e-03, -2.2474e-02, -2.1445e-02, -9.7488e-03,  3.5204e-02,\n",
            "        -2.9080e-02, -2.0864e-02, -2.2878e-02, -3.5219e-02, -3.4121e-02,\n",
            "         1.2918e-02, -1.6491e-02, -1.2597e-02, -1.7954e-02, -8.4869e-03,\n",
            "         8.7625e-03, -3.0968e-02,  2.6562e-02, -2.7699e-02, -2.7906e-02,\n",
            "         3.2565e-02, -2.6491e-02,  2.8941e-02,  1.2382e-02,  9.2508e-03,\n",
            "         2.6102e-02,  1.3786e-02,  5.5100e-03, -3.1293e-02,  1.3752e-02,\n",
            "        -8.7628e-03,  5.7600e-03, -7.7277e-04,  1.0952e-02, -6.8115e-03,\n",
            "        -2.8878e-02, -2.0727e-02, -4.9255e-03, -2.1935e-02,  3.4850e-02,\n",
            "         5.7131e-03, -2.8091e-02,  9.8892e-03, -1.2756e-03, -6.7040e-03,\n",
            "         2.6747e-02, -2.7731e-02,  3.3643e-02,  1.1210e-02,  1.5889e-02,\n",
            "        -3.1909e-02,  1.9008e-02,  7.6682e-03,  6.0628e-03,  1.0530e-03,\n",
            "         7.2056e-03, -1.5807e-02, -2.0418e-02,  1.5129e-02,  1.8804e-02,\n",
            "        -6.9031e-03, -7.4367e-03,  2.6509e-02, -3.2745e-02, -6.0320e-03,\n",
            "        -2.0327e-02, -2.4900e-02,  1.4090e-02,  2.0193e-02, -8.6754e-03,\n",
            "        -2.7913e-02,  1.3990e-02, -1.0803e-02, -3.2460e-02,  2.8141e-02,\n",
            "        -2.5895e-02, -5.6621e-03,  3.0230e-02,  2.7363e-02, -2.5160e-02,\n",
            "         1.0969e-02,  2.0814e-02,  1.9094e-02, -2.2113e-02,  2.9160e-02,\n",
            "         1.0595e-02, -1.3934e-02, -2.3805e-02,  8.6829e-03,  1.6634e-02,\n",
            "         3.3504e-02,  3.1557e-02, -2.4811e-02,  1.6728e-02,  1.8786e-02,\n",
            "        -1.7391e-02,  3.3417e-02, -1.9916e-02, -2.6515e-02,  2.4907e-02,\n",
            "        -2.1661e-02,  3.5321e-02, -6.8720e-03,  8.0134e-03,  5.5116e-03,\n",
            "         7.9799e-03,  1.6645e-02,  2.2698e-02,  1.7432e-02,  1.4445e-02,\n",
            "         8.8488e-03,  2.4190e-03,  2.1874e-02,  3.0151e-03,  3.2700e-02,\n",
            "         7.6271e-03,  2.7356e-02, -1.5953e-03,  2.9201e-02,  2.0132e-02,\n",
            "        -1.2546e-02, -1.2859e-02, -2.7403e-02, -2.5740e-02,  3.4575e-02,\n",
            "        -3.6081e-03,  9.4747e-03,  3.1798e-02,  2.1492e-02,  5.9820e-03,\n",
            "         2.5257e-02, -2.6649e-02, -1.0648e-03, -2.3665e-02,  1.7140e-02,\n",
            "         3.0635e-02,  3.5535e-02, -3.1845e-02,  2.2201e-02, -1.8065e-02,\n",
            "         1.5977e-02,  2.9789e-02,  1.6473e-02, -2.9271e-02,  2.9987e-02,\n",
            "         3.5423e-02,  3.2240e-02, -2.1014e-02,  3.3766e-02,  1.4975e-02,\n",
            "        -2.0536e-03, -3.4286e-02,  2.4041e-02, -2.0903e-02, -6.9309e-03,\n",
            "        -1.1709e-03,  3.1894e-02,  1.1881e-02, -5.1964e-03,  2.0709e-02,\n",
            "        -3.1500e-02, -3.0799e-02,  1.1722e-02, -3.4266e-02, -3.0963e-02,\n",
            "        -1.9301e-02, -2.6376e-04, -1.7453e-02, -2.9721e-02,  3.4600e-02,\n",
            "        -1.8095e-02,  5.4804e-03,  1.2384e-02,  2.3452e-02, -1.2138e-02,\n",
            "        -1.6669e-02, -3.0144e-02,  4.9334e-03,  3.2551e-02, -2.5436e-02,\n",
            "        -8.6608e-03,  9.3292e-03, -1.6469e-02,  1.4183e-02,  1.0626e-02,\n",
            "        -4.7420e-03,  5.4752e-03, -1.4519e-02, -5.6967e-03, -1.7975e-02,\n",
            "         1.0497e-02, -2.5630e-02, -4.3036e-03, -3.1056e-02,  1.4617e-04,\n",
            "         1.3361e-02,  2.5151e-02, -1.3158e-03,  1.3984e-02, -2.6510e-02,\n",
            "         3.1048e-03,  9.1612e-03, -1.3594e-02,  1.9045e-02, -6.2588e-03,\n",
            "         2.2187e-02, -9.9313e-03,  1.4449e-02, -3.4272e-02,  2.7273e-02,\n",
            "         2.0152e-02, -2.7080e-02, -2.2160e-02,  2.0040e-02, -1.7401e-02,\n",
            "         3.2933e-02,  1.0071e-02, -1.2514e-02, -3.3319e-02, -1.4064e-02,\n",
            "        -2.6595e-02,  1.0616e-02, -3.3361e-02,  1.7311e-02,  2.1937e-03,\n",
            "         3.3577e-02, -8.0222e-03, -1.7706e-02, -2.1227e-02,  7.8665e-03,\n",
            "        -1.6605e-02, -2.6005e-03,  1.4395e-02, -1.4579e-02, -5.8778e-03,\n",
            "        -3.1266e-02, -3.2917e-03, -1.5713e-02,  3.2912e-02, -2.9797e-02,\n",
            "        -6.1612e-03, -2.7937e-02, -3.3268e-02, -1.8609e-03, -1.2048e-02,\n",
            "        -2.6739e-02, -8.6128e-03,  2.0220e-02, -3.1138e-02, -6.2428e-03,\n",
            "         1.3624e-02,  2.1412e-02,  1.0073e-02, -2.9135e-02,  2.0890e-02,\n",
            "         3.8091e-04,  3.5595e-02, -5.2387e-03, -2.9820e-02,  2.2984e-02,\n",
            "         6.2045e-04, -1.0468e-02,  2.9833e-03,  2.1158e-02,  2.4079e-03,\n",
            "         1.8060e-02, -3.1751e-02, -7.9575e-03,  9.2556e-03,  2.2042e-02,\n",
            "        -1.3353e-02,  2.0075e-02, -2.0327e-02, -2.4784e-02,  2.7860e-02,\n",
            "        -2.6994e-02,  2.7219e-02,  1.4134e-02, -1.7932e-02,  2.0256e-02,\n",
            "         3.1113e-02, -3.0009e-02, -3.4434e-02,  9.1879e-03, -2.5775e-02,\n",
            "        -5.6686e-03,  5.8852e-03, -1.1670e-03,  3.3326e-02, -1.6137e-02,\n",
            "         3.0178e-02,  1.0434e-02, -5.7108e-04, -1.2734e-02, -9.8964e-03,\n",
            "         9.1282e-03, -1.9770e-02, -1.4415e-02, -1.8958e-02,  2.4055e-02,\n",
            "        -2.6426e-03, -2.4274e-03,  5.9651e-03, -7.5048e-03, -2.1395e-02,\n",
            "        -1.6547e-02, -1.0761e-02, -6.6778e-04,  4.4974e-03,  1.8297e-02,\n",
            "         2.8665e-02, -2.5108e-02, -1.0535e-03, -2.0817e-03, -3.1867e-02,\n",
            "        -3.0003e-02,  1.0454e-02,  2.6263e-02, -1.6283e-02, -3.5314e-02,\n",
            "        -1.9493e-02,  2.1566e-02, -4.1052e-03,  3.4444e-02,  2.9442e-02,\n",
            "        -2.2901e-02, -1.0658e-02, -6.5904e-03, -2.1982e-02,  1.3884e-02,\n",
            "         1.2910e-03,  3.5222e-02, -2.5543e-02,  5.1844e-03,  1.6011e-02,\n",
            "         1.0954e-02,  1.0011e-02,  3.2765e-02,  3.1263e-02, -1.3755e-02,\n",
            "        -8.0581e-03,  4.5469e-03,  3.0456e-02, -4.2459e-04, -1.2809e-02,\n",
            "         2.4448e-02,  2.2259e-03,  7.6202e-04,  1.3821e-02,  2.6385e-02,\n",
            "        -1.3095e-02,  3.6511e-03, -2.3234e-02,  2.9486e-03,  2.9334e-02,\n",
            "         8.1628e-03, -1.2110e-02, -1.5072e-02, -1.4934e-02,  4.6414e-03,\n",
            "         3.0601e-02, -3.0899e-02], requires_grad=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.0868e-03,  2.6068e-02,  3.0116e-03,  ...,  2.3046e-02,\n",
              "          3.0558e-02,  2.7585e-02],\n",
              "        [ 2.1503e-02, -3.1856e-02,  3.2216e-02,  ...,  1.7353e-02,\n",
              "          1.1927e-02, -1.0294e-02],\n",
              "        [ 1.0987e-02, -9.9699e-03, -3.2709e-02,  ..., -2.7462e-02,\n",
              "          1.2825e-02, -6.8808e-03],\n",
              "        ...,\n",
              "        [-1.8730e-02,  3.2761e-05, -3.4977e-02,  ..., -2.8589e-03,\n",
              "          1.9963e-02,  2.8916e-02],\n",
              "        [-9.3056e-03,  3.2783e-02,  4.4921e-03,  ..., -2.7229e-02,\n",
              "          1.3071e-02, -2.8241e-04],\n",
              "        [-3.4494e-02, -2.9606e-03,  2.2455e-04,  ..., -2.1973e-02,\n",
              "         -2.3918e-02,  4.4296e-03]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}